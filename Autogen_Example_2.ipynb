{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a928b4f0-1c7c-414a-8470-4a646d1aa923",
   "metadata": {},
   "source": [
    "# Autogen Group chat architecture \n",
    "A simple example of the group chat architecture to solve a task.\n",
    "\n",
    "Please set your OpenAI API key and AgentOps key in a local .env file for load_dotenv():\n",
    "```\n",
    "OPENAI_API_KEY=sk...\n",
    "AGENTOPS_API_KEY=\n",
    "```\n",
    "or set it in the environment explicity using \n",
    "```\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk...\"\n",
    "os.environ[\"AGENTOPS_API_KEY\"] = \"..\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b299866-07b9-4045-a1e7-eea7efb35ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f1a9fc4-c3a4-4407-bbd6-65554292ad31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /Users/arunesh/github/llm_agents/lab01_release/.venv/lib/python3.11/site-packages (5.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: arxiv in /Users/arunesh/github/llm_agents/lab01_release/.venv/lib/python3.11/site-packages (2.1.3)\n",
      "Requirement already satisfied: feedparser in /Users/arunesh/github/llm_agents/lab01_release/.venv/lib/python3.11/site-packages (6.0.11)\n",
      "Collecting tabulate\n",
      "  Using cached tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Requirement already satisfied: requests~=2.32.0 in /Users/arunesh/github/llm_agents/lab01_release/.venv/lib/python3.11/site-packages (from arxiv) (2.32.3)\n",
      "Requirement already satisfied: sgmllib3k in /Users/arunesh/github/llm_agents/lab01_release/.venv/lib/python3.11/site-packages (from feedparser) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/arunesh/github/llm_agents/lab01_release/.venv/lib/python3.11/site-packages (from requests~=2.32.0->arxiv) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/arunesh/github/llm_agents/lab01_release/.venv/lib/python3.11/site-packages (from requests~=2.32.0->arxiv) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/arunesh/github/llm_agents/lab01_release/.venv/lib/python3.11/site-packages (from requests~=2.32.0->arxiv) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/arunesh/github/llm_agents/lab01_release/.venv/lib/python3.11/site-packages (from requests~=2.32.0->arxiv) (2024.8.30)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.9.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install lxml\n",
    "!pip3 install arxiv feedparser tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eed15fdf-7832-4746-abb2-9530c3459cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ–‡ AgentOps:  WARNING: agentops is out of date. Please update with the command: 'pip install --upgrade agentops'\n",
      "ðŸ–‡ AgentOps: \u001b[34m\u001b[34mSession Replay: https://app.agentops.ai/drilldown?session_id=7792b2b2-0e6e-4bf1-9650-1677f04620c2\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<agentops.session.Session at 0x1042b0450>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import agentops\n",
    "\n",
    "from autogen import ConversableAgent\n",
    "agentops.init(os.environ.get(\"AGENTOPS_API_KEY\"), default_tags=[\"autogen-example-2\"])\n",
    "\n",
    "# Ref: https://colab.research.google.com/github/autogenhub/autogen/blob/main/notebook/agentchat_groupchat_research.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f5f4b78-38db-4fd4-af84-60182d083460",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_config_list = {\"config_list\": [{\"model\": \"gpt-4\", \"temperature\": 0.9, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "81f86302-6d9b-4426-bd62-19322b2f19a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen \n",
    "\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"Admin\",\n",
    "    system_message=\"A human admin. Interact with the planner to discuss the plan. Plan execution needs to be approved by this admin.\",\n",
    "    code_execution_config=False,\n",
    ")\n",
    "engineer = autogen.AssistantAgent(\n",
    "    name=\"Engineer\",\n",
    "    llm_config=gpt4_config_list,\n",
    "    system_message=\"\"\"Engineer. You follow an approved plan. You write python/shell code to solve tasks. Wrap the code in a code block that specifies the script type. The user can't modify your code. So do not suggest incomplete code which requires others to modify. Don't use a code block if it's not intended to be executed by the executor.\n",
    "Don't include multiple code blocks in one response. Do not ask others to copy and paste the result. Check the execution result returned by the executor.\n",
    "If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\n",
    "\"\"\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "947af6da-745a-421a-929a-33807d93561c",
   "metadata": {},
   "outputs": [],
   "source": [
    "executor = autogen.UserProxyAgent(\n",
    "    name=\"Executor\",\n",
    "    system_message=\"Executor. Execute the code written by the engineer and report the result.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config={\n",
    "        \"last_n_messages\": 3,\n",
    "        \"work_dir\": \"paper\",\n",
    "        \"use_docker\": False,\n",
    "    },  # Please set use_docker=True if docker is available to run the generated code. Using docker is safer than running the generated code directly.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00911701-464f-4563-ab86-0ed196fa3ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "planner = autogen.AssistantAgent(\n",
    "    name=\"Planner\",\n",
    "    system_message=\"\"\"Planner. Suggest a plan. Revise the plan based on feedback from admin and critic, until admin approval.\n",
    "The plan may involve an engineer who can write code.\n",
    "Explain the plan first. Be clear which step is performed by an engineer and when admin (user) approval is needed.\n",
    "\"\"\",\n",
    "    llm_config=gpt4_config_list,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e74954f6-ff1a-4a76-bb8e-9885da3b5a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupchat = autogen.GroupChat(\n",
    "    agents=[user_proxy, engineer, planner, executor], messages=[], max_round=50\n",
    ")\n",
    "manager = autogen.GroupChatManager(groupchat=groupchat, llm_config=gpt4_config_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5b1b78a5-c962-4f30-82d0-d89a66b4e983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mAdmin\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "find papers on LLM applications from arxiv in the last 2 months, create a markdown table of different domains.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Planner\n",
      "\u001b[0m\n",
      "\u001b[33mPlanner\u001b[0m (to chat_manager):\n",
      "\n",
      "Plan Explanation:\n",
      "\n",
      "Step 1 - Engineer:\n",
      "An engineer will write a script to fetch papers on LLM (Lifetime Learning Machines) applications from arXiv.\n",
      "\n",
      "Step 2 - Engineer/Admin (User):\n",
      "The script will filter the fetched papers to include only those published in the last 2 months. The engineer will run the script and generate a list of papers.\n",
      "\n",
      "Step 3 - Admin Approval:\n",
      "The admin will review and approve the list of papers.\n",
      "\n",
      "Step 4 - Engineer:\n",
      "The engineer will categorize the papers based on different domains (e.g., Machine Learning, Computer Science, etc.). \n",
      "\n",
      "Step 5 - Engineer:\n",
      "The engineer will then write another script to generate a markdown table. This table will include fields such as the title of the paper, authors, arXiv link, and domain.\n",
      "\n",
      "Step 6 - Admin Approval:\n",
      "The admin will review and approve the markdown table. The admin can request revisions if needed, such as including additional information or modifying the format of the table.\n",
      "\n",
      "Step 7 - Engineer:\n",
      "Make the necessary changes based on the feedback received. \n",
      "\n",
      "Step 8 - Final Admin Approval:\n",
      "The admin reviews and approves the final markdown table.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Admin\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Replying as Admin. Provide feedback to chat_manager. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  yes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mAdmin\u001b[0m (to chat_manager):\n",
      "\n",
      "yes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Engineer\n",
      "\u001b[0m\n",
      "\u001b[33mEngineer\u001b[0m (to chat_manager):\n",
      "\n",
      "First, we'll need to define what is meant by \"LLM applications\" in the context of arXiv papers. ArXiv is an online repository of scientific papers and the term \"LLM\" can have different meanings in different scientific domains. Therefore, I will assume that we are talking about papers that involve \"Lifetime Learning Machines\". This will be our search query.\n",
      "\n",
      "We will use arXiv API for Python to fetch the papers. \n",
      "\n",
      "Here is a Python script to fetch papers related to \"Lifetime Learning Machines\" from arXiv in the last 2 months:\n",
      "\n",
      "```python\n",
      "from datetime import date, timedelta\n",
      "import arxiv\n",
      "\n",
      "# Calculate the date 2 months ago\n",
      "two_months_ago = date.today() - timedelta(days=60)\n",
      "\n",
      "# Search for papers\n",
      "search = arxiv.Search(\n",
      "  query=\"Lifetime Learning Machines\",\n",
      "  max_results=1000,\n",
      "  sort_by=arxiv.SortCriterion.Relevance\n",
      ")\n",
      "\n",
      "papers = []\n",
      "for result in search.get():\n",
      "  # Check if the paper was published in the last 2 months\n",
      "  if result.published >= two_months_ago:\n",
      "    papers.append({\n",
      "      'title': result.title,\n",
      "      'authors': ', '.join(author.name for author in result.authors),\n",
      "      'link': result.entry_id,\n",
      "      'published': result.published,\n",
      "      'summary': result.summary,\n",
      "      'categories': [category.term for category in result.categories]\n",
      "    })\n",
      "\n",
      "# Print the number of papers found\n",
      "print(len(papers), \"papers found.\")\n",
      "```\n",
      "\n",
      "This script will output the number of papers found. We can then proceed to the next step which is categorizing these papers based on the domain and creating a markdown table. This requires additional code and can be done once we have fetched the papers. \n",
      "\n",
      "Please run this Python code which fetches the papers first. Then, we will proceed to the next steps.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Executor\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33mExecutor\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: \n",
      "Traceback (most recent call last):\n",
      "  File \"\", line 15, in <module>\n",
      "    for result in search.get():\n",
      "                  ^^^^^^^^^^\n",
      "AttributeError: 'Search' object has no attribute 'get'\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Engineer\n",
      "\u001b[0m\n",
      "\u001b[33mEngineer\u001b[0m (to chat_manager):\n",
      "\n",
      "I apologize for the error. The arxiv API has been updated and now it supports iteration directly on the `Search` object. Let's correct the search method and try again. Here is the updated Python script:\n",
      "\n",
      "```python\n",
      "from datetime import datetime, timedelta\n",
      "import arxiv\n",
      "\n",
      "# Calculate the date 2 months ago\n",
      "two_months_ago = (datetime.now() - timedelta(days=60)).date()\n",
      "\n",
      "# Instantiate a client\n",
      "client = arxiv.Client()\n",
      "\n",
      "# Search for papers\n",
      "search = arxiv.Search(\n",
      "  query=\"Lifetime Learning Machines\",\n",
      "  max_results=1000,\n",
      "  sort_by=arxiv.SortCriterion.Relevance\n",
      ")\n",
      "\n",
      "papers = []\n",
      "for result in search.results():\n",
      "  # Check if the paper was published in the last 2 months\n",
      "  if result.published.date() >= two_months_ago:\n",
      "    papers.append({\n",
      "      'title': result.title,\n",
      "      'authors': ', '.join(author.name for author in result.authors),\n",
      "      'link': result.entry_id,\n",
      "      'published': result.published,\n",
      "      'summary': result.summary,\n",
      "      'categories': ', '.join(category for category in result.categories)\n",
      "    })\n",
      "\n",
      "# Print the number of papers found\n",
      "print(len(papers), \"papers found.\")\n",
      "```\n",
      "\n",
      "This script fetches the papers related to \"Lifetime Learning Machines\" from arXiv and filters them based on the publication date (only include those published in the last 2 months). It then adds each paper's data into a list of papers. Each paper's data includes the title, authors, link, published date, summary, and categories. \n",
      "\n",
      "Please run this Python code to fetch the papers.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Executor\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33mExecutor\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "20 papers found.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Admin\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Replying as Admin. Provide feedback to chat_manager. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAdmin\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Engineer\n",
      "\u001b[0m\n",
      "\u001b[33mEngineer\u001b[0m (to chat_manager):\n",
      "\n",
      "Great! We have successfully fetched 20 papers related to \"Lifetime Learning Machines\" that were published in the last two months on arXiv. \n",
      "\n",
      "Now, let's proceed to categorizing these papers based on their domains or categories and creating a markdown table. This table will include fields such as the title of the paper, authors, arXiv link, published date, and domain.\n",
      "\n",
      "Here is the Python script to generate the markdown table:\n",
      "\n",
      "```python\n",
      "# Function to convert data to markdown table format\n",
      "def to_markdown_table(data, headers):\n",
      "    table = ' | '.join(headers) + '\\n' + ' | '.join('-' * len(h) for h in headers) + '\\n'\n",
      "    for row in data:\n",
      "        table += ' | '.join(str(row[h]) for h in headers) + '\\n'\n",
      "    return table\n",
      "\n",
      "# Headers for the table\n",
      "headers = ['Title', 'Authors', 'Link', 'Published', 'Domains']\n",
      "\n",
      "# Prepare the data for the table\n",
      "table_data = []\n",
      "for paper in papers:\n",
      "    table_data.append({\n",
      "        'Title': paper['title'],\n",
      "        'Authors': paper['authors'],\n",
      "        'Link': paper['link'],\n",
      "        'Published': paper['published'],\n",
      "        'Domains': paper['categories']\n",
      "    })\n",
      "\n",
      "# Convert the data to markdown table format\n",
      "markdown_table = to_markdown_table(table_data, headers)\n",
      "\n",
      "# Print the markdown table\n",
      "print(markdown_table)\n",
      "```\n",
      "\n",
      "This script generates a markdown table from the list of papers. Each row of the table corresponds to a paper and each column corresponds to a field (title, authors, link, published date, and domains).\n",
      "\n",
      "Please run this Python code which generates the markdown table.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Executor\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33mExecutor\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 1 (execution failed)\n",
      "Code output: \n",
      "Traceback (most recent call last):\n",
      "  File \"\", line 13, in <module>\n",
      "    for paper in papers:\n",
      "                 ^^^^^^\n",
      "NameError: name 'papers' is not defined\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Engineer\n",
      "\u001b[0m\n",
      "\u001b[33mEngineer\u001b[0m (to chat_manager):\n",
      "\n",
      "I realize the mistake. The papers variable is not defined in the second block of code because variables are not shared across different code executions. To solve this, we should include all the necessary code in a single block. Here is the combined Python code that fetches the papers and generates the markdown table:\n",
      "\n",
      "```python\n",
      "from datetime import datetime, timedelta\n",
      "import arxiv\n",
      "\n",
      "# Function to convert data to markdown table format\n",
      "def to_markdown_table(data, headers):\n",
      "    table = ' | '.join(headers) + '\\n' + ' | '.join('-' * len(h) for h in headers) + '\\n'\n",
      "    for row in data:\n",
      "        table += ' | '.join(str(row[h]) for h in headers) + '\\n'\n",
      "    return table\n",
      "\n",
      "# Calculate the date 2 months ago\n",
      "two_months_ago = (datetime.now() - timedelta(days=60)).date()\n",
      "\n",
      "# Instantiate a client\n",
      "client = arxiv.Client()\n",
      "\n",
      "# Search for papers\n",
      "search = arxiv.Search(\n",
      "  query=\"Lifetime Learning Machines\",\n",
      "  max_results=1000,\n",
      "  sort_by=arxiv.SortCriterion.Relevance\n",
      ")\n",
      "\n",
      "papers = []\n",
      "for result in search.results():\n",
      "  # Check if the paper was published in the last 2 months\n",
      "  if result.published.date() >= two_months_ago:\n",
      "    papers.append({\n",
      "      'title': result.title,\n",
      "      'authors': ', '.join(author.name for author in result.authors),\n",
      "      'link': result.entry_id,\n",
      "      'published': result.published,\n",
      "      'summary': result.summary,\n",
      "      'categories': ', '.join(category for category in result.categories)\n",
      "    })\n",
      "\n",
      "# Headers for the table\n",
      "headers = ['Title', 'Authors', 'Link', 'Published', 'Domains']\n",
      "\n",
      "# Prepare the data for the table\n",
      "table_data = []\n",
      "for paper in papers:\n",
      "    table_data.append({\n",
      "        'Title': paper['title'],\n",
      "        'Authors': paper['authors'],\n",
      "        'Link': paper['link'],\n",
      "        'Published': paper['published'],\n",
      "        'Domains': paper['categories']\n",
      "    })\n",
      "\n",
      "# Convert the data to markdown table format\n",
      "markdown_table = to_markdown_table(table_data, headers)\n",
      "\n",
      "# Print the markdown table\n",
      "print(markdown_table)\n",
      "```\n",
      "\n",
      "This script first fetches the papers related to \"Lifetime Learning Machines\" from arXiv and filters them based on the publication date. It then generates a markdown table from the list of papers.\n",
      "\n",
      "Please run this Python code to fetch the papers and generate the markdown table.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Executor\n",
      "\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33mExecutor\u001b[0m (to chat_manager):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "Title | Authors | Link | Published | Domains\n",
      "----- | ------- | ---- | --------- | -------\n",
      "Sparse Low-Ranked Self-Attention Transformer for Remaining Useful Lifetime Prediction of Optical Fiber Amplifiers | Dominic Schneider, Lutz Rapp | http://arxiv.org/abs/2409.14378v2 | 2024-09-22 09:48:45+00:00 | cs.LG, cs.AI, eess.SP\n",
      "Comparing Differentiable and Dynamic Ray Tracing: Introducing the Multipath Lifetime Map | JÃ©rome Eertmans, Enrico Maria Vittuci, Vittorio Degli Esposti, Laurent Jacques, Claude Oestges | http://arxiv.org/abs/2410.14535v2 | 2024-10-18 15:23:29+00:00 | eess.SP, cs.LG, 51-08, D.2.2; D.2.8; D.2.13\n",
      "Energy-Aware Federated Learning in Satellite Constellations | Nasrin Razmi, Bho Matthiesen, Armin Dekorsy, Petar Popovski | http://arxiv.org/abs/2409.14832v1 | 2024-09-23 09:01:17+00:00 | cs.DC, cs.LG, eess.SP\n",
      "Enhancing Trust in Clinically Significant Prostate Cancer Prediction with Multiple Magnetic Resonance Imaging Modalities | Benjamin Ng, Chi-en Amy Tai, E. Zhixuan Zeng, Alexander Wong | http://arxiv.org/abs/2411.04662v1 | 2024-11-07 12:48:27+00:00 | cs.LG\n",
      "Compressing Recurrent Neural Networks for FPGA-accelerated Implementation in Fluorescence Lifetime Imaging | Ismail Erbas, Vikas Pandey, Aporva Amarnath, Naigang Wang, Karthik Swaminathan, Stefan T. Radev, Xavier Intes | http://arxiv.org/abs/2410.00948v1 | 2024-10-01 17:23:26+00:00 | eess.IV, cs.LG, q-bio.QM\n",
      "Geometric Signatures of Compositionality Across a Language Model's Lifetime | Jin Hwa Lee, Thomas Jiralerspong, Lei Yu, Yoshua Bengio, Emily Cheng | http://arxiv.org/abs/2410.01444v2 | 2024-10-02 11:54:06+00:00 | cs.CL, cs.AI, cs.IT, cs.LG, math.IT\n",
      "SambaMixer: State of Health Prediction of Li-ion Batteries using Mamba State Space Models | JosÃ© Ignacio Olalde-Verano, Sascha Kirch, Clara PÃ©rez-Molina, Sergio Martin | http://arxiv.org/abs/2411.00233v1 | 2024-10-31 22:12:27+00:00 | cs.LG\n",
      "NeoPhysIx: An Ultra Fast 3D Physical Simulator as Development Tool for AI Algorithms | JÃ¶rn Fischer, Thomas Ihme | http://arxiv.org/abs/2411.05799v1 | 2024-10-26 09:53:07+00:00 | cs.RO, cs.AI, cs.LG\n",
      "Unlocking Real-Time Fluorescence Lifetime Imaging: Multi-Pixel Parallelism for FPGA-Accelerated Processing | Ismail Erbas, Aporva Amarnath, Vikas Pandey, Karthik Swaminathan, Naigang Wang, Xavier Intes | http://arxiv.org/abs/2410.07364v1 | 2024-10-09 18:24:23+00:00 | physics.optics, cs.AI, cs.DC, cs.LG\n",
      "Physics-based inverse modeling of battery degradation with Bayesian methods | Micha C. J. Philipp, Yannick Kuhn, Arnulf Latz, Birger Horstmann | http://arxiv.org/abs/2410.19478v1 | 2024-10-25 11:14:30+00:00 | physics.chem-ph, physics.app-ph\n",
      "Designing tungsten armoured plasma facing components to pulsed heat loads in magnetic fusion machines | R Mitteau, M Diez, M Firdaouss | http://arxiv.org/abs/2410.13269v1 | 2024-10-17 06:44:38+00:00 | physics.plasm-ph\n",
      "GeoLife+: Large-Scale Simulated Trajectory Datasets Calibrated to the GeoLife Dataset | Hossein Amiri, Richard Yang, Andreas Zufle | http://arxiv.org/abs/2410.11853v1 | 2024-10-02 15:01:13+00:00 | cs.DB, cs.IR, cs.LG, cs.SI\n",
      "IceCloudNet: 3D reconstruction of cloud ice from Meteosat SEVIRI | Kai Jeggle, Mikolaj Czerkawski, Federico Serva, Bertrand Le Saux, David Neubauer, Ulrike Lohmann | http://arxiv.org/abs/2410.04135v1 | 2024-10-05 12:15:38+00:00 | physics.ao-ph, cs.AI, cs.CV, J.2\n",
      "The Milky Way Radial Metallicity Gradient as an Equilibrium Phenomenon: Why Old Stars are Metal-Rich | James W. Johnson, David H. Weinberg, Guillermo A. Blanc, Ana Bonaca, Gwen C. Rudie, Yuxi, Lu, Bronwyn Reichardt Chu, Emily J. Griffith, Tawny Sit, Jennifer A. Johnson, Liam O. Dubay, Miqaela K. Weller, Daniel A. Boyea, Jonathan C. Bird | http://arxiv.org/abs/2410.13256v1 | 2024-10-17 06:27:36+00:00 | astro-ph.GA, astro-ph.CO\n",
      "Inverse Problems and Data Assimilation: A Machine Learning Approach | Eviatar Bach, Ricardo Baptista, Daniel Sanz-Alonso, Andrew Stuart | http://arxiv.org/abs/2410.10523v1 | 2024-10-14 14:01:35+00:00 | stat.ML, cs.LG, math.OC\n",
      "Symmetry-Enriched Learning: A Category-Theoretic Framework for Robust Machine Learning Models | Ronald Katende | http://arxiv.org/abs/2409.12100v1 | 2024-09-18 16:20:57+00:00 | cs.LG\n",
      "Quantum Machine Learning: An Interplay Between Quantum Computing and Machine Learning | Jun Qi, Chao-Han Yang, Samuel Yen-Chi Chen, Pin-Yu Chen | http://arxiv.org/abs/2411.09403v1 | 2024-11-14 12:27:50+00:00 | quant-ph, cs.AI\n",
      "Proactive Fraud Defense: Machine Learning's Evolving Role in Protecting Against Online Fraud | Md Kamrul Hasan Chy | http://arxiv.org/abs/2410.20281v1 | 2024-10-26 21:34:28+00:00 | cs.LG\n",
      "Identification and Mitigating Bias in Quantum Machine Learning | Nandhini Swaminathan, David Danks | http://arxiv.org/abs/2409.19011v1 | 2024-09-23 21:31:16+00:00 | quant-ph, cs.AI, cs.LG\n",
      "The State of Julia for Scientific Machine Learning | Edward Berman, Jacob Ginesin | http://arxiv.org/abs/2410.10908v1 | 2024-10-14 01:43:23+00:00 | cs.LG, cs.MS, cs.PL\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Admin\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Replying as Admin. Provide feedback to chat_manager. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAdmin\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Admin\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Replying as Admin. Provide feedback to chat_manager. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\n",
      ">>>>>>>> NO HUMAN INPUT RECEIVED.\u001b[0m\n",
      "\u001b[31m\n",
      ">>>>>>>> USING AUTO REPLY...\u001b[0m\n",
      "\u001b[33mAdmin\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[32m\n",
      "Next speaker: Admin\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Replying as Admin. Provide feedback to chat_manager. Press enter to skip and use auto-reply, or type 'exit' to end the conversation:  exit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ChatResult(chat_id=None, chat_history=[{'content': '\\nfind papers on LLM applications from arxiv in the last 2 months, create a markdown table of different domains.\\n', 'role': 'assistant', 'name': 'Admin'}, {'content': 'Plan Explanation:\\n\\nStep 1 - Engineer:\\nAn engineer will write a script to fetch papers on LLM (Lifetime Learning Machines) applications from arXiv.\\n\\nStep 2 - Engineer/Admin (User):\\nThe script will filter the fetched papers to include only those published in the last 2 months. The engineer will run the script and generate a list of papers.\\n\\nStep 3 - Admin Approval:\\nThe admin will review and approve the list of papers.\\n\\nStep 4 - Engineer:\\nThe engineer will categorize the papers based on different domains (e.g., Machine Learning, Computer Science, etc.). \\n\\nStep 5 - Engineer:\\nThe engineer will then write another script to generate a markdown table. This table will include fields such as the title of the paper, authors, arXiv link, and domain.\\n\\nStep 6 - Admin Approval:\\nThe admin will review and approve the markdown table. The admin can request revisions if needed, such as including additional information or modifying the format of the table.\\n\\nStep 7 - Engineer:\\nMake the necessary changes based on the feedback received. \\n\\nStep 8 - Final Admin Approval:\\nThe admin reviews and approves the final markdown table.', 'name': 'Planner', 'role': 'user'}, {'content': 'yes', 'role': 'assistant', 'name': 'Admin'}, {'content': 'First, we\\'ll need to define what is meant by \"LLM applications\" in the context of arXiv papers. ArXiv is an online repository of scientific papers and the term \"LLM\" can have different meanings in different scientific domains. Therefore, I will assume that we are talking about papers that involve \"Lifetime Learning Machines\". This will be our search query.\\n\\nWe will use arXiv API for Python to fetch the papers. \\n\\nHere is a Python script to fetch papers related to \"Lifetime Learning Machines\" from arXiv in the last 2 months:\\n\\n```python\\nfrom datetime import date, timedelta\\nimport arxiv\\n\\n# Calculate the date 2 months ago\\ntwo_months_ago = date.today() - timedelta(days=60)\\n\\n# Search for papers\\nsearch = arxiv.Search(\\n  query=\"Lifetime Learning Machines\",\\n  max_results=1000,\\n  sort_by=arxiv.SortCriterion.Relevance\\n)\\n\\npapers = []\\nfor result in search.get():\\n  # Check if the paper was published in the last 2 months\\n  if result.published >= two_months_ago:\\n    papers.append({\\n      \\'title\\': result.title,\\n      \\'authors\\': \\', \\'.join(author.name for author in result.authors),\\n      \\'link\\': result.entry_id,\\n      \\'published\\': result.published,\\n      \\'summary\\': result.summary,\\n      \\'categories\\': [category.term for category in result.categories]\\n    })\\n\\n# Print the number of papers found\\nprint(len(papers), \"papers found.\")\\n```\\n\\nThis script will output the number of papers found. We can then proceed to the next step which is categorizing these papers based on the domain and creating a markdown table. This requires additional code and can be done once we have fetched the papers. \\n\\nPlease run this Python code which fetches the papers first. Then, we will proceed to the next steps.', 'name': 'Engineer', 'role': 'user'}, {'content': 'exitcode: 1 (execution failed)\\nCode output: \\nTraceback (most recent call last):\\n  File \"\", line 15, in <module>\\n    for result in search.get():\\n                  ^^^^^^^^^^\\nAttributeError: \\'Search\\' object has no attribute \\'get\\'\\n', 'name': 'Executor', 'role': 'user'}, {'content': 'I apologize for the error. The arxiv API has been updated and now it supports iteration directly on the `Search` object. Let\\'s correct the search method and try again. Here is the updated Python script:\\n\\n```python\\nfrom datetime import datetime, timedelta\\nimport arxiv\\n\\n# Calculate the date 2 months ago\\ntwo_months_ago = (datetime.now() - timedelta(days=60)).date()\\n\\n# Instantiate a client\\nclient = arxiv.Client()\\n\\n# Search for papers\\nsearch = arxiv.Search(\\n  query=\"Lifetime Learning Machines\",\\n  max_results=1000,\\n  sort_by=arxiv.SortCriterion.Relevance\\n)\\n\\npapers = []\\nfor result in search.results():\\n  # Check if the paper was published in the last 2 months\\n  if result.published.date() >= two_months_ago:\\n    papers.append({\\n      \\'title\\': result.title,\\n      \\'authors\\': \\', \\'.join(author.name for author in result.authors),\\n      \\'link\\': result.entry_id,\\n      \\'published\\': result.published,\\n      \\'summary\\': result.summary,\\n      \\'categories\\': \\', \\'.join(category for category in result.categories)\\n    })\\n\\n# Print the number of papers found\\nprint(len(papers), \"papers found.\")\\n```\\n\\nThis script fetches the papers related to \"Lifetime Learning Machines\" from arXiv and filters them based on the publication date (only include those published in the last 2 months). It then adds each paper\\'s data into a list of papers. Each paper\\'s data includes the title, authors, link, published date, summary, and categories. \\n\\nPlease run this Python code to fetch the papers.', 'name': 'Engineer', 'role': 'user'}, {'content': 'exitcode: 0 (execution succeeded)\\nCode output: \\n20 papers found.\\n', 'name': 'Executor', 'role': 'user'}, {'content': '', 'role': 'assistant', 'name': 'Admin'}, {'content': 'Great! We have successfully fetched 20 papers related to \"Lifetime Learning Machines\" that were published in the last two months on arXiv. \\n\\nNow, let\\'s proceed to categorizing these papers based on their domains or categories and creating a markdown table. This table will include fields such as the title of the paper, authors, arXiv link, published date, and domain.\\n\\nHere is the Python script to generate the markdown table:\\n\\n```python\\n# Function to convert data to markdown table format\\ndef to_markdown_table(data, headers):\\n    table = \\' | \\'.join(headers) + \\'\\\\n\\' + \\' | \\'.join(\\'-\\' * len(h) for h in headers) + \\'\\\\n\\'\\n    for row in data:\\n        table += \\' | \\'.join(str(row[h]) for h in headers) + \\'\\\\n\\'\\n    return table\\n\\n# Headers for the table\\nheaders = [\\'Title\\', \\'Authors\\', \\'Link\\', \\'Published\\', \\'Domains\\']\\n\\n# Prepare the data for the table\\ntable_data = []\\nfor paper in papers:\\n    table_data.append({\\n        \\'Title\\': paper[\\'title\\'],\\n        \\'Authors\\': paper[\\'authors\\'],\\n        \\'Link\\': paper[\\'link\\'],\\n        \\'Published\\': paper[\\'published\\'],\\n        \\'Domains\\': paper[\\'categories\\']\\n    })\\n\\n# Convert the data to markdown table format\\nmarkdown_table = to_markdown_table(table_data, headers)\\n\\n# Print the markdown table\\nprint(markdown_table)\\n```\\n\\nThis script generates a markdown table from the list of papers. Each row of the table corresponds to a paper and each column corresponds to a field (title, authors, link, published date, and domains).\\n\\nPlease run this Python code which generates the markdown table.', 'name': 'Engineer', 'role': 'user'}, {'content': 'exitcode: 1 (execution failed)\\nCode output: \\nTraceback (most recent call last):\\n  File \"\", line 13, in <module>\\n    for paper in papers:\\n                 ^^^^^^\\nNameError: name \\'papers\\' is not defined\\n', 'name': 'Executor', 'role': 'user'}, {'content': 'I realize the mistake. The papers variable is not defined in the second block of code because variables are not shared across different code executions. To solve this, we should include all the necessary code in a single block. Here is the combined Python code that fetches the papers and generates the markdown table:\\n\\n```python\\nfrom datetime import datetime, timedelta\\nimport arxiv\\n\\n# Function to convert data to markdown table format\\ndef to_markdown_table(data, headers):\\n    table = \\' | \\'.join(headers) + \\'\\\\n\\' + \\' | \\'.join(\\'-\\' * len(h) for h in headers) + \\'\\\\n\\'\\n    for row in data:\\n        table += \\' | \\'.join(str(row[h]) for h in headers) + \\'\\\\n\\'\\n    return table\\n\\n# Calculate the date 2 months ago\\ntwo_months_ago = (datetime.now() - timedelta(days=60)).date()\\n\\n# Instantiate a client\\nclient = arxiv.Client()\\n\\n# Search for papers\\nsearch = arxiv.Search(\\n  query=\"Lifetime Learning Machines\",\\n  max_results=1000,\\n  sort_by=arxiv.SortCriterion.Relevance\\n)\\n\\npapers = []\\nfor result in search.results():\\n  # Check if the paper was published in the last 2 months\\n  if result.published.date() >= two_months_ago:\\n    papers.append({\\n      \\'title\\': result.title,\\n      \\'authors\\': \\', \\'.join(author.name for author in result.authors),\\n      \\'link\\': result.entry_id,\\n      \\'published\\': result.published,\\n      \\'summary\\': result.summary,\\n      \\'categories\\': \\', \\'.join(category for category in result.categories)\\n    })\\n\\n# Headers for the table\\nheaders = [\\'Title\\', \\'Authors\\', \\'Link\\', \\'Published\\', \\'Domains\\']\\n\\n# Prepare the data for the table\\ntable_data = []\\nfor paper in papers:\\n    table_data.append({\\n        \\'Title\\': paper[\\'title\\'],\\n        \\'Authors\\': paper[\\'authors\\'],\\n        \\'Link\\': paper[\\'link\\'],\\n        \\'Published\\': paper[\\'published\\'],\\n        \\'Domains\\': paper[\\'categories\\']\\n    })\\n\\n# Convert the data to markdown table format\\nmarkdown_table = to_markdown_table(table_data, headers)\\n\\n# Print the markdown table\\nprint(markdown_table)\\n```\\n\\nThis script first fetches the papers related to \"Lifetime Learning Machines\" from arXiv and filters them based on the publication date. It then generates a markdown table from the list of papers.\\n\\nPlease run this Python code to fetch the papers and generate the markdown table.', 'name': 'Engineer', 'role': 'user'}, {'content': \"exitcode: 0 (execution succeeded)\\nCode output: \\nTitle | Authors | Link | Published | Domains\\n----- | ------- | ---- | --------- | -------\\nSparse Low-Ranked Self-Attention Transformer for Remaining Useful Lifetime Prediction of Optical Fiber Amplifiers | Dominic Schneider, Lutz Rapp | http://arxiv.org/abs/2409.14378v2 | 2024-09-22 09:48:45+00:00 | cs.LG, cs.AI, eess.SP\\nComparing Differentiable and Dynamic Ray Tracing: Introducing the Multipath Lifetime Map | JÃ©rome Eertmans, Enrico Maria Vittuci, Vittorio Degli Esposti, Laurent Jacques, Claude Oestges | http://arxiv.org/abs/2410.14535v2 | 2024-10-18 15:23:29+00:00 | eess.SP, cs.LG, 51-08, D.2.2; D.2.8; D.2.13\\nEnergy-Aware Federated Learning in Satellite Constellations | Nasrin Razmi, Bho Matthiesen, Armin Dekorsy, Petar Popovski | http://arxiv.org/abs/2409.14832v1 | 2024-09-23 09:01:17+00:00 | cs.DC, cs.LG, eess.SP\\nEnhancing Trust in Clinically Significant Prostate Cancer Prediction with Multiple Magnetic Resonance Imaging Modalities | Benjamin Ng, Chi-en Amy Tai, E. Zhixuan Zeng, Alexander Wong | http://arxiv.org/abs/2411.04662v1 | 2024-11-07 12:48:27+00:00 | cs.LG\\nCompressing Recurrent Neural Networks for FPGA-accelerated Implementation in Fluorescence Lifetime Imaging | Ismail Erbas, Vikas Pandey, Aporva Amarnath, Naigang Wang, Karthik Swaminathan, Stefan T. Radev, Xavier Intes | http://arxiv.org/abs/2410.00948v1 | 2024-10-01 17:23:26+00:00 | eess.IV, cs.LG, q-bio.QM\\nGeometric Signatures of Compositionality Across a Language Model's Lifetime | Jin Hwa Lee, Thomas Jiralerspong, Lei Yu, Yoshua Bengio, Emily Cheng | http://arxiv.org/abs/2410.01444v2 | 2024-10-02 11:54:06+00:00 | cs.CL, cs.AI, cs.IT, cs.LG, math.IT\\nSambaMixer: State of Health Prediction of Li-ion Batteries using Mamba State Space Models | JosÃ© Ignacio Olalde-Verano, Sascha Kirch, Clara PÃ©rez-Molina, Sergio Martin | http://arxiv.org/abs/2411.00233v1 | 2024-10-31 22:12:27+00:00 | cs.LG\\nNeoPhysIx: An Ultra Fast 3D Physical Simulator as Development Tool for AI Algorithms | JÃ¶rn Fischer, Thomas Ihme | http://arxiv.org/abs/2411.05799v1 | 2024-10-26 09:53:07+00:00 | cs.RO, cs.AI, cs.LG\\nUnlocking Real-Time Fluorescence Lifetime Imaging: Multi-Pixel Parallelism for FPGA-Accelerated Processing | Ismail Erbas, Aporva Amarnath, Vikas Pandey, Karthik Swaminathan, Naigang Wang, Xavier Intes | http://arxiv.org/abs/2410.07364v1 | 2024-10-09 18:24:23+00:00 | physics.optics, cs.AI, cs.DC, cs.LG\\nPhysics-based inverse modeling of battery degradation with Bayesian methods | Micha C. J. Philipp, Yannick Kuhn, Arnulf Latz, Birger Horstmann | http://arxiv.org/abs/2410.19478v1 | 2024-10-25 11:14:30+00:00 | physics.chem-ph, physics.app-ph\\nDesigning tungsten armoured plasma facing components to pulsed heat loads in magnetic fusion machines | R Mitteau, M Diez, M Firdaouss | http://arxiv.org/abs/2410.13269v1 | 2024-10-17 06:44:38+00:00 | physics.plasm-ph\\nGeoLife+: Large-Scale Simulated Trajectory Datasets Calibrated to the GeoLife Dataset | Hossein Amiri, Richard Yang, Andreas Zufle | http://arxiv.org/abs/2410.11853v1 | 2024-10-02 15:01:13+00:00 | cs.DB, cs.IR, cs.LG, cs.SI\\nIceCloudNet: 3D reconstruction of cloud ice from Meteosat SEVIRI | Kai Jeggle, Mikolaj Czerkawski, Federico Serva, Bertrand Le Saux, David Neubauer, Ulrike Lohmann | http://arxiv.org/abs/2410.04135v1 | 2024-10-05 12:15:38+00:00 | physics.ao-ph, cs.AI, cs.CV, J.2\\nThe Milky Way Radial Metallicity Gradient as an Equilibrium Phenomenon: Why Old Stars are Metal-Rich | James W. Johnson, David H. Weinberg, Guillermo A. Blanc, Ana Bonaca, Gwen C. Rudie, Yuxi, Lu, Bronwyn Reichardt Chu, Emily J. Griffith, Tawny Sit, Jennifer A. Johnson, Liam O. Dubay, Miqaela K. Weller, Daniel A. Boyea, Jonathan C. Bird | http://arxiv.org/abs/2410.13256v1 | 2024-10-17 06:27:36+00:00 | astro-ph.GA, astro-ph.CO\\nInverse Problems and Data Assimilation: A Machine Learning Approach | Eviatar Bach, Ricardo Baptista, Daniel Sanz-Alonso, Andrew Stuart | http://arxiv.org/abs/2410.10523v1 | 2024-10-14 14:01:35+00:00 | stat.ML, cs.LG, math.OC\\nSymmetry-Enriched Learning: A Category-Theoretic Framework for Robust Machine Learning Models | Ronald Katende | http://arxiv.org/abs/2409.12100v1 | 2024-09-18 16:20:57+00:00 | cs.LG\\nQuantum Machine Learning: An Interplay Between Quantum Computing and Machine Learning | Jun Qi, Chao-Han Yang, Samuel Yen-Chi Chen, Pin-Yu Chen | http://arxiv.org/abs/2411.09403v1 | 2024-11-14 12:27:50+00:00 | quant-ph, cs.AI\\nProactive Fraud Defense: Machine Learning's Evolving Role in Protecting Against Online Fraud | Md Kamrul Hasan Chy | http://arxiv.org/abs/2410.20281v1 | 2024-10-26 21:34:28+00:00 | cs.LG\\nIdentification and Mitigating Bias in Quantum Machine Learning | Nandhini Swaminathan, David Danks | http://arxiv.org/abs/2409.19011v1 | 2024-09-23 21:31:16+00:00 | quant-ph, cs.AI, cs.LG\\nThe State of Julia for Scientific Machine Learning | Edward Berman, Jacob Ginesin | http://arxiv.org/abs/2410.10908v1 | 2024-10-14 01:43:23+00:00 | cs.LG, cs.MS, cs.PL\\n\\n\", 'name': 'Executor', 'role': 'user'}, {'content': '', 'role': 'assistant', 'name': 'Admin'}, {'content': '', 'role': 'assistant', 'name': 'Admin'}], summary='', cost={'usage_including_cached_inference': {'total_cost': 0}, 'usage_excluding_cached_inference': {'total_cost': 0}}, human_input=['yes', '', '', '', 'exit'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_proxy.initiate_chat(\n",
    "    manager,\n",
    "    message=\"\"\"\n",
    "find papers on LLM applications from arxiv in the last 2 months, create a markdown table of different domains.\n",
    "\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d822c16-9d80-409c-aa5f-4b5c79a51baa",
   "metadata": {},
   "source": [
    "Title | Authors | Link | Published | Domains\n",
    "----- | ------- | ---- | --------- | -------\n",
    "Sparse Low-Ranked Self-Attention Transformer for Remaining Useful Lifetime Prediction of Optical Fiber Amplifiers | Dominic Schneider, Lutz Rapp | http://arxiv.org/abs/2409.14378v2 | 2024-09-22 09:48:45+00:00 | cs.LG, cs.AI, eess.SP\n",
    "Comparing Differentiable and Dynamic Ray Tracing: Introducing the Multipath Lifetime Map | JÃ©rome Eertmans, Enrico Maria Vittuci, Vittorio Degli Esposti, Laurent Jacques, Claude Oestges | http://arxiv.org/abs/2410.14535v2 | 2024-10-18 15:23:29+00:00 | eess.SP, cs.LG, 51-08, D.2.2; D.2.8; D.2.13\n",
    "Energy-Aware Federated Learning in Satellite Constellations | Nasrin Razmi, Bho Matthiesen, Armin Dekorsy, Petar Popovski | http://arxiv.org/abs/2409.14832v1 | 2024-09-23 09:01:17+00:00 | cs.DC, cs.LG, eess.SP\n",
    "Enhancing Trust in Clinically Significant Prostate Cancer Prediction with Multiple Magnetic Resonance Imaging Modalities | Benjamin Ng, Chi-en Amy Tai, E. Zhixuan Zeng, Alexander Wong | http://arxiv.org/abs/2411.04662v1 | 2024-11-07 12:48:27+00:00 | cs.LG\n",
    "Compressing Recurrent Neural Networks for FPGA-accelerated Implementation in Fluorescence Lifetime Imaging | Ismail Erbas, Vikas Pandey, Aporva Amarnath, Naigang Wang, Karthik Swaminathan, Stefan T. Radev, Xavier Intes | http://arxiv.org/abs/2410.00948v1 | 2024-10-01 17:23:26+00:00 | eess.IV, cs.LG, q-bio.QM\n",
    "Geometric Signatures of Compositionality Across a Language Model's Lifetime | Jin Hwa Lee, Thomas Jiralerspong, Lei Yu, Yoshua Bengio, Emily Cheng | http://arxiv.org/abs/2410.01444v2 | 2024-10-02 11:54:06+00:00 | cs.CL, cs.AI, cs.IT, cs.LG, math.IT\n",
    "SambaMixer: State of Health Prediction of Li-ion Batteries using Mamba State Space Models | JosÃ© Ignacio Olalde-Verano, Sascha Kirch, Clara PÃ©rez-Molina, Sergio Martin | http://arxiv.org/abs/2411.00233v1 | 2024-10-31 22:12:27+00:00 | cs.LG\n",
    "NeoPhysIx: An Ultra Fast 3D Physical Simulator as Development Tool for AI Algorithms | JÃ¶rn Fischer, Thomas Ihme | http://arxiv.org/abs/2411.05799v1 | 2024-10-26 09:53:07+00:00 | cs.RO, cs.AI, cs.LG\n",
    "Unlocking Real-Time Fluorescence Lifetime Imaging: Multi-Pixel Parallelism for FPGA-Accelerated Processing | Ismail Erbas, Aporva Amarnath, Vikas Pandey, Karthik Swaminathan, Naigang Wang, Xavier Intes | http://arxiv.org/abs/2410.07364v1 | 2024-10-09 18:24:23+00:00 | physics.optics, cs.AI, cs.DC, cs.LG\n",
    "Physics-based inverse modeling of battery degradation with Bayesian methods | Micha C. J. Philipp, Yannick Kuhn, Arnulf Latz, Birger Horstmann | http://arxiv.org/abs/2410.19478v1 | 2024-10-25 11:14:30+00:00 | physics.chem-ph, physics.app-ph\n",
    "Designing tungsten armoured plasma facing components to pulsed heat loads in magnetic fusion machines | R Mitteau, M Diez, M Firdaouss | http://arxiv.org/abs/2410.13269v1 | 2024-10-17 06:44:38+00:00 | physics.plasm-ph\n",
    "GeoLife+: Large-Scale Simulated Trajectory Datasets Calibrated to the GeoLife Dataset | Hossein Amiri, Richard Yang, Andreas Zufle | http://arxiv.org/abs/2410.11853v1 | 2024-10-02 15:01:13+00:00 | cs.DB, cs.IR, cs.LG, cs.SI\n",
    "IceCloudNet: 3D reconstruction of cloud ice from Meteosat SEVIRI | Kai Jeggle, Mikolaj Czerkawski, Federico Serva, Bertrand Le Saux, David Neubauer, Ulrike Lohmann | http://arxiv.org/abs/2410.04135v1 | 2024-10-05 12:15:38+00:00 | physics.ao-ph, cs.AI, cs.CV, J.2\n",
    "The Milky Way Radial Metallicity Gradient as an Equilibrium Phenomenon: Why Old Stars are Metal-Rich | James W. Johnson, David H. Weinberg, Guillermo A. Blanc, Ana Bonaca, Gwen C. Rudie, Yuxi, Lu, Bronwyn Reichardt Chu, Emily J. Griffith, Tawny Sit, Jennifer A. Johnson, Liam O. Dubay, Miqaela K. Weller, Daniel A. Boyea, Jonathan C. Bird | http://arxiv.org/abs/2410.13256v1 | 2024-10-17 06:27:36+00:00 | astro-ph.GA, astro-ph.CO\n",
    "Inverse Problems and Data Assimilation: A Machine Learning Approach | Eviatar Bach, Ricardo Baptista, Daniel Sanz-Alonso, Andrew Stuart | http://arxiv.org/abs/2410.10523v1 | 2024-10-14 14:01:35+00:00 | stat.ML, cs.LG, math.OC\n",
    "Symmetry-Enriched Learning: A Category-Theoretic Framework for Robust Machine Learning Models | Ronald Katende | http://arxiv.org/abs/2409.12100v1 | 2024-09-18 16:20:57+00:00 | cs.LG\n",
    "Quantum Machine Learning: An Interplay Between Quantum Computing and Machine Learning | Jun Qi, Chao-Han Yang, Samuel Yen-Chi Chen, Pin-Yu Chen | http://arxiv.org/abs/2411.09403v1 | 2024-11-14 12:27:50+00:00 | quant-ph, cs.AI\n",
    "Proactive Fraud Defense: Machine Learning's Evolving Role in Protecting Against Online Fraud | Md Kamrul Hasan Chy | http://arxiv.org/abs/2410.20281v1 | 2024-10-26 21:34:28+00:00 | cs.LG\n",
    "Identification and Mitigating Bias in Quantum Machine Learning | Nandhini Swaminathan, David Danks | http://arxiv.org/abs/2409.19011v1 | 2024-09-23 21:31:16+00:00 | quant-ph, cs.AI, cs.LG\n",
    "The State of Julia for Scientific Machine Learning | Edward Berman, Jacob Ginesin | http://arxiv.org/abs/2410.10908v1 | 2024-10-14 01:43:23+00:00 | cs.LG, cs.MS, cs.PL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9109f27-8d2c-4e15-b483-9d7ced2a2c67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc57a27-d3db-4992-b063-a72f748b074b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
