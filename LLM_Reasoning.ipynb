{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9705725-7008-4cd2-a168-f1be2b36215d",
   "metadata": {},
   "source": [
    "# LLM Reasoning Experiments\n",
    "\n",
    "The experiment below shows the non-determinstic nature of LLMs. It also shows how reasoning can help it converge\n",
    "to the right answer. This can also be used to confirm the \"Consistency\" principle outlined in Lecture 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d79b1d0-ea4f-432e-b0e7-e994a664b4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf51153-7ee6-4ae0-937e-32a1c90d3de8",
   "metadata": {},
   "source": [
    "## Few-shot prompting and no reasoning\n",
    "Run this to see how gpt-4o produces the incorrect answer using just few-shot (2 examples) prompting. Note that running\n",
    "this on ChatGPT might produce different results since that model has \"reasoning\" based prompting logic built into its system message as a default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "759defb7-6eef-4f56-ab86-a96f8c75f62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "------------------------------------\n",
      "Response: “ck”\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "Response: “ac”\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "Response: “ck”\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "Response: “ck”\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "Response: The answer is \"ac\". The pattern in the examples involves taking the last two letters of the first name and the last two letters of the last name, and moving to the previous letters in the alphabet for each pair. For \"Barack Obama\":\n",
      "\n",
      "- From \"ac\" in \"Barack\", the previous two letters are still \"ac\".\n",
      "- From \"ma\" in \"Obama\", the previous two letters are still \"ma\".\n",
      "\n",
      "So the answer remains \"ac\".\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "Response: The pattern involves taking the last two letters of the first name and the last two letters of the last name. For \"Barack Obama,\" the last two letters of the first name are \"ck\" and the last two letters of the last name are \"ma.\" Therefore, the answer is \"ckma.\"\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "Response: The pattern appears to involve taking the middle letters from the first name and extracting them as the answer:\n",
      "\n",
      "- \"Elon Musk\": Taking the middle letters from \"Elon\": 'l' and 'o', then reversing them to \"nk\".\n",
      "- \"Bill Gates\": Taking the middle letters from \"Bill\": 'i' and 'l', then reversing them to \"ls\".\n",
      "\n",
      "Following the observed pattern:\n",
      "\n",
      "- \"Barack Obama\": Taking the middle letters from \"Barack\": 'a' and 'r', then reversing them to \"ra\".\n",
      "\n",
      "Therefore, the answer would be \"ra\".\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "Response: “ck”\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "Response: The pattern here seems to be taking the second and second-to-last letter of the person's first and last name and joining them together. \n",
      "\n",
      "- For \"Elon Musk\": second letter is 'l', second-to-last letter is 'n' → \"ln\"\n",
      "- For \"Bill Gates\": second letter is 'i', second-to-last letter is 'l' → \"il\"\n",
      "\n",
      "Revised pattern:\n",
      "- Remove second-to-last letter from the pattern and using first name's 2nd letter followed by last name's 2nd letter.\n",
      "\n",
      "So, for \"Barack Obama\":\n",
      "- Second letter of \"Barack\" is 'a'\n",
      "- Second letter of \"Obama\" is 'b'\n",
      "\n",
      "A: \"ab\"\n",
      "\n",
      "\n",
      "------------------------------------\n",
      "Response: \"ck\"\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# https://platform.openai.com/docs/api-reference/chat/create\n",
    "\n",
    "USER_QUERY = \"\"\"\n",
    "Q: “Elon Musk” A: “nk”\n",
    "Q: “Bill Gates” A: “ls”\n",
    "Q: “Barack Obama” A: ?\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def run_user_query_oai_model(model_str, user_query):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model_str,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI Assistant.\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"name\": \"Joe\",\n",
    "                \"content\": user_query\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message\n",
    "    \n",
    "def run_user_query_oai(user_query):\n",
    "    return run_user_query_oai_model(\"gpt-4o\", user_query)\n",
    "\n",
    "for i in range(1, 11):\n",
    "    print(\"\\n\\n------------------------------------\")\n",
    "    print(\"Response:\", run_user_query_oai(USER_QUERY).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07951ee3-36e6-4b85-98db-a16c45950f5b",
   "metadata": {},
   "source": [
    "# Chain of thought with reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59ac79a4-1253-4580-b73e-d5faba8ee14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: ChatCompletionMessage(content='To solve this puzzle, we need to look at the pattern in how each name is transformed into an answer based on the examples given.\\n\\nLet\\'s analyze the transformations:\\n\\n1. **Elon Musk** becomes **nk**:\\n   - We take the last letter of the first name \"Elon\" which is \"n\".\\n   - We take the last letter of the last name \"Musk\" which is \"k\".\\n   - Combine these letters, and we get \"nk\".\\n\\n2. **Bill Gates** becomes **ls**:\\n   - We take the last letter of the first name \"Bill\" which is \"l\".\\n   - We take the last letter of the last name \"Gates\" which is \"s\".\\n   - Combine these letters, and we get \"ls\".\\n\\nFollowing this pattern:\\n\\n3. **Barack Obama**:\\n   - Take the last letter of the first name \"Barack\" which is \"k\".\\n   - Take the last letter of the last name \"Obama\" which is \"a\".\\n   - Combine these letters, and we get \"ka\".\\n\\nTherefore, the answer for \"Barack Obama\" is \"ka\".', refusal=None, role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "USER_QUERY_WITH_CHAIN_OF_THOUGHT = \"\"\"\n",
    "Q: “Elon Musk” A: “nk”\n",
    "Q: “Bill Gates” A: “ls”\n",
    "Q: “Barack Obama” A: ?\n",
    "Provide a reason and arrive at the solution step by step.\n",
    "\"\"\"\n",
    "print(\"Response:\", run_user_query_oai(USER_QUERY_WITH_CHAIN_OF_THOUGHT).content)\n",
    "# Prints the correct answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c75fa700-fca4-4773-bb22-c3e6b5661870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: To solve this problem, we need to first determine the number of golf balls the juggler is juggling. Since the juggler has 16 balls in total and half of them are golf balls:\n",
      "\n",
      "\\[\n",
      "\\text{Number of golf balls} = \\frac{16}{2} = 8\n",
      "\\]\n",
      "\n",
      "Now, since half of the golf balls are blue, we calculate the number of blue golf balls:\n",
      "\n",
      "\\[\n",
      "\\text{Number of blue golf balls} = \\frac{8}{2} = 4\n",
      "\\]\n",
      "\n",
      "Therefore, the number of blue golf balls is 4.\n",
      "\n",
      "The answer (in Arabic numerals) is 4.\n"
     ]
    }
   ],
   "source": [
    "# Lets see if it thinks step by step.\n",
    "COT_WITH_EXAMPLES = \"\"\"\n",
    "Q: A juggler can juggle 16 balls. Half of the balls are golf balls, and half of the golfs balls are blue. How many blue golf balls are there ?\n",
    "A: The answer (arabic numerals) is\n",
    "\"\"\"\n",
    "print(\"Response:\", run_user_query_oai_model(\"gpt-4o\", COT_WITH_EXAMPLES).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a4c91cf-5c82-4987-ae1a-5c86d5caf48c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: Janet's ducks lay 16 eggs per day. She uses 3 eggs for breakfast and 4 eggs for baking muffins, which totals 7 eggs each day. \n",
      "\n",
      "So, the number of eggs she has left to sell each day is:\n",
      "\n",
      "\\[ 16 - 7 = 9 \\text{ eggs} \\]\n",
      "\n",
      "She sells these 9 eggs at $2 per egg, so her earnings each day are:\n",
      "\n",
      "\\[ 9 \\times 2 = 18 \\text{ dollars} \\]\n",
      "\n",
      "Janet makes $18 every day from selling the eggs.\n"
     ]
    }
   ],
   "source": [
    "# Self consistency Example \n",
    "SELF_CONSISTENCY_PROMPT = \"\"\"\n",
    "Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four.\n",
    "She sells the remainder for $2 per egg. How much does she make every day ?\n",
    "\"\"\"\n",
    "print(\"Response:\", run_user_query_oai_model(\"gpt-4o\", SELF_CONSISTENCY_PROMPT).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "53037524-23f2-4dfd-ac40-e43b797b7500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: To calculate Lucy's bank balance after the transactions, we start with the initial amount she had in the bank, which is $65. \n",
      "\n",
      "Lucy made a $15 deposit, so we add $15 to her balance: $65 + $15 = $80\n",
      "\n",
      "Then she made a $4 withdrawal, so we subtract $4 from her balance: $80 - $4 = $76\n",
      "\n",
      "Next, we consider Maria's expenses for the month. Maria's rent is $10, and utilities cost $3. So, we subtract these expenses from Lucy's balance: $76 - $10 - $3 = $63\n",
      "\n",
      "Therefore, after all the transactions and expenses, Lucy's bank balance is $63.\n"
     ]
    }
   ],
   "source": [
    "# Irrelevant context example, how irrelevant context can cause LLMs to err. Correct answer is $76 \n",
    "# GPT-3.5-turbo makes more errors than gpt-4o\n",
    "\n",
    "IRRELEVANT_CONTEXT_PROMPT = \"\"\"\n",
    "Lucy has $65 in the bank. She made a $15 deposit and then followed by a $4 withdrawal. Maria's monthly rent is $10. And another $3 for utilities for Maria. What is Lucky's bank balance?\n",
    "\"\"\"\n",
    "print(\"Response:\", run_user_query_oai_model(\"gpt-3.5-turbo\", IRRELEVANT_CONTEXT_PROMPT).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d569e33e-9d8d-4ef9-9871-2ea7c8300e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
