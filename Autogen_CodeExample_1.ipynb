{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16cf5873-4eea-468f-9375-16b660abb41d",
   "metadata": {},
   "source": [
    "# Autogen code executor \n",
    "Simple example of python code execution using Autogen.\n",
    "\n",
    "Please set your OpenAI API key and AgentOps key in a local .env file for load_dotenv():\n",
    "```\n",
    "OPENAI_API_KEY=sk...\n",
    "AGENTOPS_API_KEY=\n",
    "```\n",
    "or set it in the environment explicity using \n",
    "```\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk...\"\n",
    "os.environ[\"AGENTOPS_API_KEY\"] = \"..\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1059f99a-1046-48d7-b2e7-0c0418ec568a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc0e9cb6-7f9c-46b4-beb0-69db78b8d1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: agentops in /Users/arunesh/github/llm_agents/.venv_1/lib/python3.11/site-packages (0.3.17)\n",
      "Collecting autogen\n",
      "  Downloading autogen-0.3.2-py3-none-any.whl (351 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.0/352.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.0.0 in /Users/arunesh/github/llm_agents/.venv_1/lib/python3.11/site-packages (from agentops) (2.32.3)\n",
      "Requirement already satisfied: psutil==5.9.8 in /Users/arunesh/github/llm_agents/.venv_1/lib/python3.11/site-packages (from agentops) (5.9.8)\n",
      "Requirement already satisfied: packaging==23.2 in /Users/arunesh/github/llm_agents/.venv_1/lib/python3.11/site-packages (from agentops) (23.2)\n",
      "Requirement already satisfied: termcolor>=2.3.0 in /Users/arunesh/github/llm_agents/.venv_1/lib/python3.11/site-packages (from agentops) (2.5.0)\n",
      "Requirement already satisfied: PyYAML<7.0,>=5.3 in /Users/arunesh/github/llm_agents/.venv_1/lib/python3.11/site-packages (from agentops) (6.0.2)\n",
      "Collecting diskcache\n",
      "  Using cached diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
      "Collecting docker\n",
      "  Using cached docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "Collecting flaml\n",
      "  Downloading FLAML-2.3.2-py3-none-any.whl (313 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.9/313.9 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy<2,>=1.17.0 in /Users/arunesh/github/llm_agents/.venv_1/lib/python3.11/site-packages (from autogen) (1.26.4)\n",
      "Requirement already satisfied: openai>=1.3 in /Users/arunesh/github/llm_agents/.venv_1/lib/python3.11/site-packages (from autogen) (1.54.4)\n",
      "Requirement already satisfied: pydantic!=2.6.0,<3,>=1.10 in /Users/arunesh/github/llm_agents/.venv_1/lib/python3.11/site-packages (from autogen) (2.9.2)\n",
      "Requirement already satisfied: python-dotenv in /Users/arunesh/github/llm_agents/.venv_1/lib/python3.11/site-packages (from autogen) (1.0.1)\n",
      "Requirement already satisfied: tiktoken in /Users/arunesh/github/llm_agents/.venv_1/lib/python3.11/site-packages (from autogen) (0.8.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/arunesh/github/llm_agents/.venv_1/lib/python3.11/site-packages (from openai>=1.3->autogen) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/arunesh/github/llm_agents/.venv_1/lib/python3.11/site-packages (from openai>=1.3->autogen) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/arunesh/github/llm_agents/.venv_1/lib/python3.11/site-packages (from openai>=1.3->autogen) (0.27.2)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/arunesh/github/llm_agents/.venv_1/lib/python3.11/site-packages (from openai>=1.3->autogen) (0.7.1)\n",
      "Requirement already satisfied: sniffio in /Users/arunesh/github/llm_agents/.venv_1/lib/python3.11/site-packages (from openai>=1.3->autogen) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/arunesh/github/llm_agents/.venv_1/lib/python3.11/site-packages (from openai>=1.3->autogen) (4.67.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/arunesh/github/llm_agents/.venv_1/lib/python3.11/site-packages (from openai>=1.3->autogen) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/arunesh/github/llm_agents/.venv_1/lib/python3.11/site-packages (from pydantic!=2.6.0,<3,>=1.10->autogen) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/arunesh/github/llm_agents/.venv_1/lib/python3.11/site-packages (from pydantic!=2.6.0,<3,>=1.10->autogen) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/arunesh/github/llm_agents/.venv_1/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->agentops) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/arunesh/github/llm_agents/.venv_1/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->agentops) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/arunesh/github/llm_agents/.venv_1/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->agentops) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/arunesh/github/llm_agents/.venv_1/lib/python3.11/site-packages (from requests<3.0.0,>=2.0.0->agentops) (2024.8.30)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /Users/arunesh/github/llm_agents/.venv_1/lib/python3.11/site-packages (from tiktoken->autogen) (2024.11.6)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/arunesh/github/llm_agents/.venv_1/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai>=1.3->autogen) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/arunesh/github/llm_agents/.venv_1/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3->autogen) (0.14.0)\n",
      "Installing collected packages: flaml, diskcache, docker, autogen\n",
      "Successfully installed autogen-0.3.2 diskcache-5.6.3 docker-7.1.0 flaml-2.3.2\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install agentops autogen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2b26917-099d-44b7-8a95-df6910953e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "🖇 AgentOps: \u001b[34m\u001b[34mSession Replay: https://app.agentops.ai/drilldown?session_id=8bc998e1-2500-47b2-9989-a92b88c2bdad\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<agentops.session.Session at 0x10f4cdd90>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import agentops\n",
    "\n",
    "from autogen import ConversableAgent\n",
    "agentops.init(os.environ.get(\"AGENTOPS_API_KEY\"), default_tags=[\"autogen-example-1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45e16750-347a-4b7c-8e43-2badcddca41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_config_list = {\"config_list\": [{\"model\": \"gpt-4\", \"temperature\": 0.9, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7adecfd4-fe1b-48ca-9204-5bbaa4504684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code writer agent's system message is to instruct the LLM on how to\n",
    "# use the Jupyter code executor with IPython kernel.\n",
    "code_writer_system_message = \"\"\"\n",
    "You have been given coding capability to solve tasks using Python code.\n",
    "In the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute.\n",
    "    1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time, check the operating system. After sufficient info is printed and the task is ready to be solved based on your language skill, you can solve the task by yourself.\n",
    "    2. When you need to perform some task with code, use the code to perform the task and output the result. Finish the task smartly.\n",
    "Solve the task step by step if you need to. If a plan is not provided, explain your plan first. Be clear which step uses code, and which step uses your language skill.\n",
    "When using code, you must indicate the script type in the code block. The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user can't modify your code. So do not suggest incomplete code which requires users to modify. Don't use a code block if it's not intended to be executed by the user.\n",
    "If you want the user to save the code in a file before executing it, put # filename: <filename> inside the code block as the first line. Don't include multiple code blocks in one response. Do not ask users to copy and paste the result. Instead, use 'print' function for the output when relevant. Check the execution result returned by the user.\n",
    "\"\"\"\n",
    "\n",
    "import os, autogen\n",
    "\n",
    "code_writer_agent = ConversableAgent(\n",
    "    \"code_writer\",\n",
    "    system_message=code_writer_system_message,\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]},\n",
    "    code_execution_config=False,  # Turn off code execution for this agent.\n",
    "    max_consecutive_auto_reply=2,\n",
    "    human_input_mode=\"NEVER\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56f4c842-e929-45d5-bf7c-a60589a397a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_executor = autogen.UserProxyAgent(\n",
    "    name=\"Executor\",\n",
    "    system_message=\"Executor. Execute the code written by the code writer and report the result.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config={\n",
    "        \"last_n_messages\": 3,\n",
    "        \"work_dir\": \"paper\",\n",
    "        \"use_docker\": False,\n",
    "    },  # Please set use_docker=True if docker is available to run the generated code. Using docker is safer than running the generated code directly.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dd5299c-7832-44b7-8c45-6000748d4198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mExecutor\u001b[0m (to code_writer):\n",
      "\n",
      "Write Python code to calculate the 14th Fibonacci number.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcode_writer\u001b[0m (to Executor):\n",
      "\n",
      "Here is a Python script that you can run to calculate the 14th Fibonacci number:\n",
      "\n",
      "```python\n",
      "def fibonacci(n):\n",
      "    if n < 0:\n",
      "        print(\"Incorrect input\")\n",
      "    elif n == 1 or n == 0:\n",
      "        return n\n",
      "    else:\n",
      "        a, b = 0, 1\n",
      "        for _ in range(2, n+1):\n",
      "            a, b = b, a + b\n",
      "        return b\n",
      "\n",
      "print(fibonacci(14))\n",
      "```\n",
      "\n",
      "This script defines a function `fibonacci(n)` that calculates the nth Fibonacci number for any n greater than or equal to zero. The function uses a loop to add up the two previous Fibonacci numbers to calculate the current one.\n",
      "\n",
      "After we define the function, we call it with `n` set to 14 to calculate the 14th Fibonacci number. The result is then printed out.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33mExecutor\u001b[0m (to code_writer):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "377\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcode_writer\u001b[0m (to Executor):\n",
      "\n",
      "The 14th Fibonacci number is 377. Great, the code has executed successfully and you've got the correct output.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[31m\n",
      ">>>>>>>> EXECUTING CODE BLOCK 0 (inferred language is python)...\u001b[0m\n",
      "\u001b[33mExecutor\u001b[0m (to code_writer):\n",
      "\n",
      "exitcode: 0 (execution succeeded)\n",
      "Code output: \n",
      "377\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ChatResult(chat_id=None,\n",
      "           chat_history=[{'content': 'Write Python code to calculate the 14th '\n",
      "                                     'Fibonacci number.',\n",
      "                          'name': 'Executor',\n",
      "                          'role': 'assistant'},\n",
      "                         {'content': 'Here is a Python script that you can run '\n",
      "                                     'to calculate the 14th Fibonacci number:\\n'\n",
      "                                     '\\n'\n",
      "                                     '```python\\n'\n",
      "                                     'def fibonacci(n):\\n'\n",
      "                                     '    if n < 0:\\n'\n",
      "                                     '        print(\"Incorrect input\")\\n'\n",
      "                                     '    elif n == 1 or n == 0:\\n'\n",
      "                                     '        return n\\n'\n",
      "                                     '    else:\\n'\n",
      "                                     '        a, b = 0, 1\\n'\n",
      "                                     '        for _ in range(2, n+1):\\n'\n",
      "                                     '            a, b = b, a + b\\n'\n",
      "                                     '        return b\\n'\n",
      "                                     '\\n'\n",
      "                                     'print(fibonacci(14))\\n'\n",
      "                                     '```\\n'\n",
      "                                     '\\n'\n",
      "                                     'This script defines a function '\n",
      "                                     '`fibonacci(n)` that calculates the nth '\n",
      "                                     'Fibonacci number for any n greater than '\n",
      "                                     'or equal to zero. The function uses a '\n",
      "                                     'loop to add up the two previous '\n",
      "                                     'Fibonacci numbers to calculate the '\n",
      "                                     'current one.\\n'\n",
      "                                     '\\n'\n",
      "                                     'After we define the function, we call it '\n",
      "                                     'with `n` set to 14 to calculate the 14th '\n",
      "                                     'Fibonacci number. The result is then '\n",
      "                                     'printed out.',\n",
      "                          'name': 'code_writer',\n",
      "                          'role': 'user'},\n",
      "                         {'content': 'exitcode: 0 (execution succeeded)\\n'\n",
      "                                     'Code output: \\n'\n",
      "                                     '377\\n',\n",
      "                          'name': 'Executor',\n",
      "                          'role': 'assistant'},\n",
      "                         {'content': 'The 14th Fibonacci number is 377. Great, '\n",
      "                                     'the code has executed successfully and '\n",
      "                                     \"you've got the correct output.\",\n",
      "                          'name': 'code_writer',\n",
      "                          'role': 'user'},\n",
      "                         {'content': 'exitcode: 0 (execution succeeded)\\n'\n",
      "                                     'Code output: \\n'\n",
      "                                     '377\\n',\n",
      "                          'name': 'Executor',\n",
      "                          'role': 'assistant'}],\n",
      "           summary='exitcode: 0 (execution succeeded)\\nCode output: \\n377\\n',\n",
      "           cost={'usage_excluding_cached_inference': {'total_cost': 0},\n",
      "                 'usage_including_cached_inference': {'gpt-4-0613': {'completion_tokens': 414,\n",
      "                                                                     'cost': 0.08195999999999999,\n",
      "                                                                     'prompt_tokens': 1904,\n",
      "                                                                     'total_tokens': 2318},\n",
      "                                                      'total_cost': 0.08195999999999999}},\n",
      "           human_input=[])\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "chat_result = code_executor.initiate_chat(\n",
    "    code_writer_agent, message=\"Write Python code to calculate the 14th Fibonacci number.\"\n",
    ")\n",
    "\n",
    "pprint.pprint(chat_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fcc099-f9e9-4caf-850f-1fe8555c84b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
